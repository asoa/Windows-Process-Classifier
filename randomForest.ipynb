{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import feature, evaluation, Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f468a620b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = (SparkConf()\n",
    "            .setAppName('random_forest')\n",
    "            .setMaster('spark://spark-master:7077')\n",
    "       )\n",
    "conf.set(\"spark.executor.memory\", \"6g\")\n",
    "conf.set(\"spark.driver.maxResultSize\", \"0\")\n",
    "conf.set(\"spark.sql.shuffle.partitions\", \"6\")\n",
    "conf.set(\"spark.default.parallelism\", \"6\")\n",
    "conf.set(\"spark.driver.memory\", \"3g\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original dataset without bootstrapped samples\n",
    "df = (spark.read.format('csv')\n",
    "      .option('inferSchema', 'true')\n",
    "      .option('header', 'true')\n",
    "      .option('escape', '\"')\n",
    "      .load('hdfs://namenode:9000/data/no_bootstrap.csv') \n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned dataset from previous model\n",
    "+ regex and split operations transform the string representation of cmd_line_tokens back to an arraytype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------+\n",
      "|cmd_line_tokens                                                  |\n",
      "+-----------------------------------------------------------------+\n",
      "|[svchost.exe, -k, localservicenonetwork, -p]                     |\n",
      "|[svchost.exe, -k, localservice, -p, -s, dispbrokerdesktopsvc]    |\n",
      "|[oobe, windeploy.exe]                                            |\n",
      "|[oobe, setup.exe]                                                |\n",
      "|[svchost.exe, -k, localservicenetworkrestricted, -p, -s, lmhosts]|\n",
      "+-----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (df.select('*')\n",
    "          .withColumn('class_label', df.class_label.cast(T.DoubleType()))\n",
    "          .withColumn('cmd_line_tokens', F.regexp_replace(F.col('cmd_line_tokens'), r\"(\\[)|(\\]|\\'|\\s+)\", ''))\n",
    "          .withColumn('cmd_line_tokens', F.split(F.col('cmd_line_tokens'), ','))\n",
    "     )\n",
    "df.select('cmd_line_tokens').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data engineering pipelines \n",
    "+ Term Frequency (one-hot): value indicates if feature is present in observation\n",
    "+ Feature has to be present at least once in dataset and in at least 50 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_transformer = feature.CountVectorizer(minTF=1, minDF=50, binary=True, inputCol='cmd_line_tokens', outputCol='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline(stages=[cv_transformer]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+---------------------------------------------+\n",
      "|cmd_line_tokens                                                        |tf                                           |\n",
      "+-----------------------------------------------------------------------+---------------------------------------------+\n",
      "|[svchost.exe, -k, localservicenonetwork, -p]                           |(288,[26,27,60],[1.0,1.0,1.0])               |\n",
      "|[svchost.exe, -k, localservice, -p, -s, dispbrokerdesktopsvc]          |(288,[26,27,60,63,120],[1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, localsystemnetworkrestricted, -p, -s, ncbservice]    |(288,[26,27,60,63,114],[1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, localservicenetworkrestricted, -p, -s, timebrokersvc]|(288,[26,27,60,63,111],[1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, netsvcs, -p, -s, themes]                             |(288,[26,27,60,63,77],[1.0,1.0,1.0,1.0,1.0]) |\n",
      "+-----------------------------------------------------------------------+---------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator.transform(df).select('cmd_line_tokens','tf').sample(.1).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(estimator.stages[0].vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol='tf', labelCol='class_label', numTrees=100, \n",
    "                            featureSubsetStrategy='sqrt', impurity='gini', seed=0)\n",
    "rf_estimator = Pipeline(stages=[cv_transformer, rf])\n",
    "rf_model = rf_estimator.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(accuracy=0.9976617303195635)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.transform(testing_df).\\\n",
    "    select(F.avg(F.expr('float(class_label = prediction)')).alias('accuracy')).\\\n",
    "    first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=dtc_d932652de21e) of depth 4 with 11 nodes\n",
      "  If (feature 162 <= 0.5)\n",
      "   If (feature 115 <= 0.5)\n",
      "    Predict: 0.0\n",
      "   Else (feature 115 > 0.5)\n",
      "    Predict: 1.0\n",
      "  Else (feature 162 > 0.5)\n",
      "   If (feature 3 <= 0.5)\n",
      "    If (feature 165 <= 0.5)\n",
      "     If (feature 20 <= 0.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 20 > 0.5)\n",
      "      Predict: 0.0\n",
      "    Else (feature 165 > 0.5)\n",
      "     Predict: 1.0\n",
      "   Else (feature 3 > 0.5)\n",
      "    Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rf_model.stages[-1].trees[1].toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The tokens with the most importance all indicate a malicious log and are very similar to the tokens identified in the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-executionpolicy</td>\n",
       "      <td>0.254961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>bypass</td>\n",
       "      <td>0.247080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>/c</td>\n",
       "      <td>0.154412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-c</td>\n",
       "      <td>0.130766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>select-object</td>\n",
       "      <td>0.119997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>net</td>\n",
       "      <td>0.035477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https</td>\n",
       "      <td>0.012194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>share</td>\n",
       "      <td>0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>/r</td>\n",
       "      <td>0.007573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>files</td>\n",
       "      <td>0.005825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x86</td>\n",
       "      <td>0.005213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>program</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>googleupdate.exe</td>\n",
       "      <td>0.002157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-f</td>\n",
       "      <td>0.001517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-s</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-embedding</td>\n",
       "      <td>0.001107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>--type</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-m</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chrome.exe</td>\n",
       "      <td>0.000653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                vocab    weight\n",
       "116  -executionpolicy  0.254961\n",
       "115            bypass  0.247080\n",
       "162                /c  0.154412\n",
       "108                -c  0.130766\n",
       "194     select-object  0.119997\n",
       "195               net  0.035477\n",
       "15              https  0.012194\n",
       "165             share  0.010667\n",
       "199                /r  0.007573\n",
       "3               files  0.005825\n",
       "4                 x86  0.005213\n",
       "2             program  0.002532\n",
       "142  googleupdate.exe  0.002157\n",
       "190                -f  0.001517\n",
       "63                 -s  0.001191\n",
       "1              google  0.001136\n",
       "19         -embedding  0.001107\n",
       "7              --type  0.000802\n",
       "192                -m  0.000673\n",
       "6          chrome.exe  0.000653"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = rf_model.stages[0].vocabulary\n",
    "feature_importance = rf_model.stages[-1].featureImportances.toArray()\n",
    "vocab_importance_df = pd.DataFrame({'vocab': vocab, 'weight': feature_importance})\n",
    "vocab_importance_df.sort_values('weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder() \n",
    "                 .addGrid(rf_model.stages[0].minDF, [25, 50, 75, 100]) \n",
    "                 .addGrid(rf_model.stages[1].numTrees, [75, 100, 150, 200]) \n",
    "                 .build()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 0\n",
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n",
      "Fitting model 10\n",
      "Fitting model 11\n",
      "Fitting model 12\n",
      "Fitting model 13\n",
      "Fitting model 14\n",
      "Fitting model 15\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for grid in range(len(paramGrid)):\n",
    "    print(\"Fitting model {}\".format(grid))\n",
    "    _model = rf_estimator.fit(validation_df, paramGrid[grid])\n",
    "    models.append(_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='class_label', metricName='areaUnderROC')\n",
    "auc_scores = [evaluator.evaluate(model.transform(validation_df)) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9996269915822306,\n",
       " 0.9996769236381544,\n",
       " 0.9995775155268174,\n",
       " 0.9995727275214548,\n",
       " 0.989375416100466,\n",
       " 0.9910815420113271,\n",
       " 0.9914331184050926,\n",
       " 0.9903273171665952,\n",
       " 0.9903223011609772,\n",
       " 0.9910081259291011,\n",
       " 0.991248666198506,\n",
       " 0.9904420012950415,\n",
       " 0.9891503798484254,\n",
       " 0.991151766089978,\n",
       " 0.9893685760928053,\n",
       " 0.9902739651068408]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: \n",
      "\n",
      "{Param(parent='CountVectorizer_64866bd78246', name='minDF', doc='Specifies the minimum number of different documents a term must appear in to be included in the vocabulary. If this is an integer >= 1, this specifies the number of documents the term must appear in; if this is a double in [0,1), then this specifies the fraction of documents. Default 1.0'): 25.0, Param(parent='RandomForestClassifier_28597608eb0b', name='numTrees', doc='Number of trees to train (>= 1)'): 100}\n",
      "\n",
      "Best AUC: \n",
      "\n",
      "0.9996769236381544\n"
     ]
    }
   ],
   "source": [
    "best_model_idx = np.argmax(auc_scores)\n",
    "best_model = models[best_model_idx]\n",
    "print(\"Best params: \\n\\n{}\\n\".format(paramGrid[best_model_idx]))\n",
    "print(\"Best AUC: \\n\\n{}\".format(auc_scores[best_model_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model\n",
    "+ minDF: 25\n",
    "+ numTrees: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "+ test best_model performance on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990428223888843"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(best_model.transform(training_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly Dash Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
